{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d3b379",
   "metadata": {},
   "source": [
    "question1\n",
    "a:A Classification Decision Tree is a supervised machine learning algorithm designed to solve classification problems. These problems involve predicting categorical outcomes or class labels based on input features. It uses a tree-like model of decisions, where each internal node represents a decision based on a feature, and each leaf node represents a predicted class.\n",
    "\n",
    "Examples of Real-World Applications:\n",
    "\n",
    "Medical Diagnosis: Determining if a patient has a particular disease (e.g., predicting \"diabetes\" or \"no diabetes\") based on factors like age, BMI, and blood sugar levels.\n",
    "Fraud Detection: Identifying whether a transaction is fraudulent or legitimate.\n",
    "Customer Segmentation: Classifying customers into groups (e.g., high-value, medium-value, low-value) based on purchase history.\n",
    "Email Filtering: Determining whether an email is spam or not spam.\n",
    "Loan Approval: Predicting if a loan applicant is likely to default or repay based on their credit history and income.\n",
    "b:\n",
    "A Classification Decision Tree predicts by breaking down a dataset into smaller subsets based on feature conditions. The process involves:\n",
    "\n",
    "Evaluating input features sequentially at decision nodes using thresholds or categories.\n",
    "Following the path dictated by the conditions until reaching a leaf node.\n",
    "Assigning the class label of the leaf node to the input data.\n",
    "For example, in a binary classification task (e.g., \"spam\" vs. \"not spam\"), the tree might first check if the email contains certain keywords. Depending on the presence or absence of those keywords, the tree evaluates further features until it confidently predicts \"spam\" or \"not spam.\"\n",
    "\n",
    "Multiple Linear Regression is used for regression problems where the output is continuous. It predicts by:\n",
    "\n",
    "Calculating a weighted sum of the input features, where each feature is multiplied by a coefficient (learned during training).\n",
    "Adding a bias term (intercept) to the weighted sum.\n",
    "Producing a numerical prediction.\n",
    "\n",
    "Summary:\n",
    "Classification Decision Tree\n",
    "Purpose: Solves classification problems by predicting categorical outcomes (e.g., \"spam\" vs. \"not spam\").\n",
    "How It Works:\n",
    "Sequentially evaluates input features using decision rules (e.g., thresholds or categories).\n",
    "Follows a path through the tree to a leaf node, which represents the predicted class.\n",
    "Examples:\n",
    "Medical diagnosis, fraud detection, email filtering, customer segmentation, and loan approval.\n",
    "Multiple Linear Regression\n",
    "Purpose: Solves regression problems by predicting continuous outcomes (e.g., house prices).\n",
    "How It Works:\n",
    "Calculates a weighted sum of input features.\n",
    "Produces a numerical prediction based on the input data.\n",
    "Key Differences:\n",
    "Output Type:\n",
    "Decision Tree: Discrete class labels.\n",
    "Linear Regression: Continuous numerical values.\n",
    "Prediction Process:\n",
    "Decision Tree: Follows hierarchical decision paths.\n",
    "Linear Regression: Uses a linear equation to compute outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b50d0",
   "metadata": {},
   "source": [
    "question2\n",
    "1. Accuracy\n",
    "\n",
    "Definition: Measures the overall correctness of the model, considering both true positives (TP) and true negatives (TN).\n",
    "Best Used For: When the cost of false positives (FP) and false negatives (FN) is similar.\n",
    "Example:\n",
    "Weather Prediction: Predicting whether it will rain or not. Both false alarms (FP) and missed predictions (FN) have relatively low stakes.\n",
    "Rationale: Accuracy gives a general sense of how often the model is correct.\n",
    "2. Sensitivity (Recall)\n",
    "\n",
    "Definition: Measures the proportion of actual positives correctly identified（TP/(TP+FN)).\n",
    "Best Used For: When identifying positives is critical, and missing them (false negatives) has severe consequences.\n",
    "Example:\n",
    "Medical Diagnosis: Detecting diseases like cancer or diabetes. Missing a positive case (FN) can have life-threatening consequences.\n",
    "Rationale: High sensitivity ensures fewer missed cases, which is vital in healthcare or safety-critical systems.\n",
    "3. Specificity\n",
    "\n",
    "Definition: Measures the proportion of actual negatives correctly identified (TN/(TN+FP)).\n",
    "Best Used For: When minimizing false positives is crucial.\n",
    "Example:\n",
    "Fraud Detection: Identifying fraudulent credit card transactions. Too many false positives (flagging legitimate transactions as fraud) can frustrate users.\n",
    "Rationale: High specificity ensures that genuine negatives are not incorrectly flagged.\n",
    "4. Precision\n",
    "\n",
    "Definition: Measures the proportion of predicted positives that are correct (TP/(TP+FP)).\n",
    "Best Used For: When false positives are costly or misleading.\n",
    "Example:\n",
    "Email Filtering: Classifying emails as spam. Incorrectly marking a legitimate email as spam (FP) can cause important communication to be missed.\n",
    "Rationale: High precision ensures that when the model predicts positive, it’s likely to be correct.\n",
    "\n",
    "Summary:\n",
    "Accuracy\n",
    "Best For: General-purpose problems where false positives (FP) and false negatives (FN) are equally costly.\n",
    "Example: Weather prediction (e.g., rain vs. no rain).\n",
    "Sensitivity (Recall)\n",
    "Best For: Detecting positives is critical, and missing them (FN) has severe consequences.\n",
    "Example: Medical diagnosis (e.g., cancer detection).\n",
    "Specificity\n",
    "Best For: Avoiding false positives is more important than missing positives.\n",
    "Example: Fraud detection (e.g., flagging credit card transactions).\n",
    "Precision\n",
    "Best For: When false positives are costly or misleading.\n",
    "Example: Email spam filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09328885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Preprocessing steps\n",
    "# 1. Remove 'Weight_oz', 'Width', and 'Height' columns\n",
    "ab = ab.drop(columns=['Weight_oz', 'Width', 'Height'], errors='ignore')\n",
    "\n",
    "# 2. Drop rows with any NaN values\n",
    "ab_reduced_noNaN = ab.dropna()\n",
    "\n",
    "# 3. Set column types\n",
    "ab_reduced_noNaN['Pub year'] = ab_reduced_noNaN['Pub year'].astype(int)\n",
    "ab_reduced_noNaN['NumPages'] = ab_reduced_noNaN['NumPages'].astype(int)\n",
    "ab_reduced_noNaN['Hard_or_Paper'] = ab_reduced_noNaN['Hard_or_Paper'].astype('category')\n",
    "\n",
    "# Display basic information about the cleaned dataset\n",
    "print(\"Dataset Summary After Preprocessing:\")\n",
    "print(ab_reduced_noNaN.info())\n",
    "print(\"\\nFirst 5 Rows of Processed Data:\")\n",
    "print(ab_reduced_noNaN.head())\n",
    "\n",
    "# Initial Exploratory Data Analysis (EDA)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(ab_reduced_noNaN.describe())\n",
    "\n",
    "# Frequency distribution for 'Hard_or_Paper'\n",
    "print(\"\\nFrequency Distribution of Hard_or_Paper:\")\n",
    "print(ab_reduced_noNaN['Hard_or_Paper'].value_counts())\n",
    "\n",
    "# Distribution of 'Pub year'\n",
    "print(\"\\nDistribution of Publication Year:\")\n",
    "print(ab_reduced_noNaN['Pub year'].value_counts().sort_index())\n",
    "\n",
    "# Visualization examples (optional, requires matplotlib/seaborn)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot distribution of NumPages\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(ab_reduced_noNaN['NumPages'], bins=30, kde=True)\n",
    "plt.title('Distribution of Number of Pages')\n",
    "plt.xlabel('NumPages')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Box plot of NumPages by Hard_or_Paper\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x='Hard_or_Paper', y='NumPages', data=ab_reduced_noNaN)\n",
    "plt.title('NumPages by Hard_or_Paper')\n",
    "plt.xlabel('Binding Type (Hard or Paper)')\n",
    "plt.ylabel('NumPages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678b827",
   "metadata": {},
   "source": [
    "Remove Columns:\n",
    "Removed Weight_oz, Width, and Height using the drop method.\n",
    "Handle Missing Values:\n",
    "Used dropna() to remove rows containing any missing values.\n",
    "Type Conversion:\n",
    "Converted Pub year and NumPages to integers using .astype(int).\n",
    "Converted Hard_or_Paper to a categorical type using .astype('category').\n",
    "EDA:\n",
    "Summarized data using .info() and .describe() for a high-level overview.\n",
    "Calculated frequency counts for the Hard_or_Paper column and distribution of Pub year.\n",
    "Visualized data using histograms and box plots to explore the distribution of numerical variables and their relationship with categorical features.\n",
    "Output Example\n",
    "Dataset Info:\n",
    "Number of rows and columns after preprocessing.\n",
    "Data types of each column.\n",
    "Summary Statistics:\n",
    "Descriptive statistics for numerical columns like NumPages.\n",
    "Frequency and Distribution:\n",
    "Frequency counts for Hard_or_Paper.\n",
    "Distribution of publication years (Pub year).\n",
    "Visualizations:\n",
    "Histogram of NumPages.\n",
    "Box plot of NumPages grouped by Hard_or_Paper.\n",
    "\n",
    "Summary:\n",
    "Preprocessing Steps:\n",
    "Removed Columns: Dropped Weight_oz, Width, and Height.\n",
    "Handled Missing Data: Removed rows with any missing (NaN) values.\n",
    "Type Conversions:\n",
    "Pub year and NumPages converted to integers.\n",
    "Hard_or_Paper converted to a categorical type.\n",
    "Dataset Overview (Post-Processing):\n",
    "The dataset's structure, column types, and non-missing row counts are displayed using .info().\n",
    "The cleaned dataset is ready for further analysis.\n",
    "Exploratory Data Analysis (EDA):\n",
    "Numerical Summary: Descriptive statistics (mean, median, min, max) provided for numerical columns like NumPages.\n",
    "Categorical Summary: Frequency counts for Hard_or_Paper (binding type).\n",
    "Distribution Analysis:\n",
    "Distribution of NumPages visualized with a histogram.\n",
    "Box plot created to analyze NumPages by Hard_or_Paper.\n",
    "Frequency of Pub year values reviewed to identify trends.\n",
    "Key Insights from EDA:\n",
    "Most books have a moderate number of pages, with some outliers (long books).\n",
    "Differences in the number of pages between hardcovers and paperbacks can be observed from the box plot.\n",
    "Pub year trends may reveal periods of higher publication activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question4\n",
    "#Step 1: Splitting the Dataset into Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = ab_reduced_noNaN[['List Price']]\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']  # 'H' represents hardcover books\n",
    "\n",
    "# Perform 80/20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Report the number of observations in each set\n",
    "print(f\"Training Set Size: {X_train.shape[0]} observations\")\n",
    "print(f\"Testing Set Size: {X_test.shape[0]} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a78de",
   "metadata": {},
   "source": [
    "Step 1: The .fit() function trains the decision tree on the training dataset. It learns decision rules based on the input features (e.g., List Price) and their relationship to the target variable (e.g., whether a book is hardcover or paperback).\n",
    "Step 2: The .predict() function uses the trained model to make predictions for unseen (test) data based on the learned rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4526a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Training and Visualizing the Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the tree\n",
    "plt.figure(figsize=(10, 5))\n",
    "tree.plot_tree(clf, feature_names=['List Price'], class_names=['Paper', 'Hard'], filled=True)\n",
    "plt.title(\"Decision Tree for Hard Cover vs. Paper Back (max_depth=2)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d0e930",
   "metadata": {},
   "source": [
    "Predictions Made by the Fitted Decision Tree\n",
    "The decision tree will split on List Price to classify books as hardcover (Hard) or paperback (Paper).\n",
    "Each Node in the Tree:\n",
    "Represents a condition (e.g., List Price <= 20).\n",
    "Shows how the model splits data into subsets based on this condition.\n",
    "Contains the predicted class (hardcover or paperback) for the leaf nodes.\n",
    "Example Explanation of Predictions:\n",
    "\n",
    "If List Price <= $20, the tree might predict \"Paper\" with a high probability.\n",
    "If List Price > $20, the tree might predict \"Hard.\"\n",
    "\n",
    "Summary:\n",
    "Data Splitting:\n",
    "The dataset was split into 80% training set (ab_reduced_noNaN_train) and 20% testing set (ab_reduced_noNaN_test) using train_test_split.\n",
    "Training Set Size: Number of observations = 80% of the dataset.\n",
    "Testing Set Size: Number of observations = 20% of the dataset.\n",
    "ChatBot Insights on Decision Tree Steps:\n",
    "Step 1 (clf.fit(X_train, y_train)): Trains the decision tree model by learning decision rules to classify books as hardcover or paperback based on List Price.\n",
    "Step 2 (clf.predict(X_test)): Uses the trained model to classify new, unseen test data.\n",
    "Model Training:\n",
    "A DecisionTreeClassifier was trained using the List Price variable to predict whether a book is hardcover (H) or paperback (P).\n",
    "The tree's maximum depth was set to 2 for simplicity and interpretability.\n",
    "Tree Visualization:\n",
    "The decision tree splits the List Price feature into intervals to make predictions:\n",
    "For example, books with a low price (e.g., ≤ $20) might be classified as \"Paperback.\"\n",
    "Books with a high price (e.g., > $20) might be classified as \"Hardcover.\"\n",
    "Each node in the tree represents a condition and a predicted class (e.g., \"Hard\" or \"Paper\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e7019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question5\n",
    "#Step 1: Training the New Decision Tree\n",
    "# Define new features (X) and the same target variable (y)\n",
    "X = ab_reduced_noNaN[['NumPages', 'Thick', 'List Price']]\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']  # 'H' for hardcover books\n",
    "\n",
    "# Train a new DecisionTreeClassifier with max_depth=4\n",
    "clf2 = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf2.fit(X_train, y_train)  # Training the model\n",
    "#Step 2: Visualizing the Decision Tree\n",
    "# Visualize the classification decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "tree.plot_tree(clf2, feature_names=['NumPages', 'Thick', 'List Price'], \n",
    "               class_names=['Paper', 'Hard'], filled=True)\n",
    "plt.title(\"Decision Tree for Hard Cover vs. Paper Back (max_depth=4)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb99b38",
   "metadata": {},
   "source": [
    "The decision tree (clf2) uses three features (NumPages, Thick, and List Price) to classify books as hardcover or paperback. Here's how predictions are made:\n",
    "\n",
    "Splitting on Features:\n",
    "At each node, the tree evaluates one feature (e.g., NumPages <= 300 or List Price > $25) and splits the data into two branches based on the condition.\n",
    "Hierarchy of Rules:\n",
    "The tree starts with the most important feature (determined by its ability to split data into distinct classes).\n",
    "At deeper levels (up to depth 4), the tree refines the classification using additional features.\n",
    "Leaf Nodes (Final Predictions):\n",
    "The tree stops splitting when a maximum depth of 4 is reached or further splits do not improve classification.\n",
    "Leaf nodes contain the predicted class (hardcover or paperback) and the probability of that class based on the training data.\n",
    "General Workflow of Predictions in clf2:\n",
    "Example 1:\n",
    "A book with NumPages = 400, Thick = 1.2, and List Price = $30:\n",
    "The tree may first evaluate List Price > $25 → Go to the \"Hardcover\" branch.\n",
    "Next, it may check NumPages > 300 → Further confirmation for \"Hardcover.\"\n",
    "Example 2:\n",
    "A book with NumPages = 150, Thick = 0.5, and List Price = $15:\n",
    "The tree may first evaluate List Price ≤ $25 → Go to the \"Paperback\" branch.\n",
    "Then, check NumPages ≤ 300 → Confirms \"Paperback.\"\n",
    "\n",
    "Summary:\n",
    "Training the Model:\n",
    "The decision tree (clf2) was trained using three features: NumPages, Thick, and List Price, to predict whether a book is hardcover or paperback.\n",
    "The tree was constrained to a maximum depth of 4 to control complexity and ensure interpretability.\n",
    "Tree Visualization:\n",
    "The decision tree visualizes how the model splits data at each node based on feature values, with the goal of classifying books into \"Hard\" (hardcover) or \"Paper\" (paperback).\n",
    "The tree uses combinations of conditions such as NumPages, Thick, and List Price to decide on the classification.\n",
    "Prediction Process:\n",
    "Splits: The tree evaluates each feature at various nodes (e.g., NumPages <= 300, List Price > $25) and divides the data into two branches.\n",
    "Leaf Nodes: After reaching the maximum depth, the tree assigns a class (hardcover or paperback) based on the conditions that were met along the path.\n",
    "Example Predictions:\n",
    "Hardcover: If List Price is high (e.g., > $25) and NumPages is large (e.g., > 300), the tree may classify the book as hardcover.\n",
    "Paperback: If List Price is lower (e.g., ≤ $25), the book is more likely to be classified as paperback, with further checks on NumPages and Thick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question6\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "\n",
    "# Predict using clf and clf2\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "y_pred_clf2 = clf2.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrices\n",
    "cm_clf = confusion_matrix(y_test, y_pred_clf)\n",
    "cm_clf2 = confusion_matrix(y_test, y_pred_clf2)\n",
    "\n",
    "# Display confusion matrices\n",
    "print(\"Confusion Matrix for clf (Decision Tree 1):\")\n",
    "print(cm_clf)\n",
    "print(\"\\nConfusion Matrix for clf2 (Decision Tree 2):\")\n",
    "print(cm_clf2)\n",
    "\n",
    "# Calculate accuracy, sensitivity, and specificity for clf\n",
    "accuracy_clf = accuracy_score(y_test, y_pred_clf)\n",
    "sensitivity_clf = recall_score(y_test, y_pred_clf)  # Sensitivity = Recall\n",
    "specificity_clf = cm_clf[1,1] / (cm_clf[1,0] + cm_clf[1,1])  # Specificity = TN / (TN + FP)\n",
    "\n",
    "# Calculate accuracy, sensitivity, and specificity for clf2\n",
    "accuracy_clf2 = accuracy_score(y_test, y_pred_clf2)\n",
    "sensitivity_clf2 = recall_score(y_test, y_pred_clf2)  # Sensitivity = Recall\n",
    "specificity_clf2 = cm_clf2[1,1] / (cm_clf2[1,0] + cm_clf2[1,1])  # Specificity = TN / (TN + FP)\n",
    "\n",
    "# Reporting results\n",
    "print(\"\\nModel clf (Decision Tree 1) Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_clf:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity_clf:.4f}\")\n",
    "print(f\"Specificity: {specificity_clf:.4f}\")\n",
    "\n",
    "print(\"\\nModel clf2 (Decision Tree 2) Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_clf2:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity_clf2:.4f}\")\n",
    "print(f\"Specificity: {specificity_clf2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47366405",
   "metadata": {},
   "source": [
    "To evaluate the models clf and clf2 using the previously created test set (ab_reduced_noNaN_test), we'll compute confusion matrices and report the sensitivity, specificity, and accuracy for each model.\n",
    "\n",
    "Steps to Evaluate and Report Metrics:\n",
    "Predictions: Make predictions on the test set using both clf and clf2.\n",
    "Confusion Matrix: Compute the confusion matrix for both models.\n",
    "Metrics Calculation: Use the confusion matrix to calculate accuracy, sensitivity, and specificity for both models.\n",
    "\n",
    "Suumary:\n",
    "Model Predictions:\n",
    "clf and clf2 made predictions on the test dataset (ab_reduced_noNaN_test).\n",
    "Confusion Matrices:\n",
    "The confusion matrix for each model is calculated, showing:\n",
    "True Positives (TP): Correctly predicted hardcover books.\n",
    "False Positives (FP): Paperback books incorrectly predicted as hardcover.\n",
    "True Negatives (TN): Correctly predicted paperback books.\n",
    "False Negatives (FN): Hardcover books incorrectly predicted as paperback.\n",
    "Performance Metrics Calculated:\n",
    "Accuracy: The proportion of correctly predicted books (hardcover and paperback) out of all predictions.\n",
    "Sensitivity (Recall): The proportion of actual hardcover books correctly classified as hardcover.\n",
    "Specificity: The proportion of actual paperback books correctly classified as paperback.\n",
    "Reported Metrics for Both Models:\n",
    "Accuracy, Sensitivity, and Specificity are reported for both clf and clf2, giving insight into the performance of each decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288818b",
   "metadata": {},
   "source": [
    "question7\n",
    "The differences between the two confusion matrices arise from the features used for training and prediction. In the first matrix, the model is predicting based solely on the List Price, which may not capture the full complexity of the data, leading to less accurate or biased predictions. In the second matrix, the model uses a broader set of features (NumPages, Thick, and List Price), allowing it to make more informed decisions by incorporating additional relevant information, leading to potentially better predictions.\n",
    "\n",
    "The confusion matrices from clf and clf2 are better because they are based on models trained with more diverse feature sets (especially in clf2, which includes three features), which allow for a more accurate understanding of the data and more robust predictions. This leads to better sensitivity, specificity, and overall accuracy when making predictions on the test set.\n",
    "\n",
    "Summary:\n",
    "Differences in Features:\n",
    "The first confusion matrix uses only List Price as the feature to predict whether a book is hardcover or paperback, which may lead to less accurate or biased predictions due to the limited information.\n",
    "The second confusion matrix includes additional features (NumPages, Thick, and List Price), providing the model with more context and allowing it to make better predictions.\n",
    "Why clf and clf2 are Better:\n",
    "The models trained in clf and clf2 use a broader set of features (especially clf2, which uses three features), leading to more informed predictions.\n",
    "This results in improved accuracy, sensitivity, and specificity on the test dataset, as the models can capture more complexity and nuances in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf81fb",
   "metadata": {},
   "source": [
    "qeustion8\n",
    "To visualize the feature importances for a scikit-learn classification decision tree, you can use the .feature_importances_ attribute of the trained model. This attribute provides the relative importance of each feature used in the model. The higher the value, the more important the feature is for the tree's decision-making process.\n",
    "\n",
    "Here's how to do it for clf2 and identify the most important predictor variable:\n",
    "\n",
    "Steps to Visualize Feature Importances:\n",
    "Access the Feature Importances: Use clf2.feature_importances_ to get the importance scores.\n",
    "Display the Feature Names: Use clf2.feature_names_in_ to see the corresponding feature names.\n",
    "Plot the Importances: Visualize the importances to get a clear understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Access the feature importances and feature names\n",
    "feature_importances = clf2.feature_importances_\n",
    "feature_names = clf2.feature_names_in_\n",
    "\n",
    "# Create a bar chart to visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, feature_importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances for clf2 (Decision Tree)')\n",
    "plt.show()\n",
    "\n",
    "# Report the most important feature\n",
    "most_important_feature = feature_names[np.argmax(feature_importances)]\n",
    "print(f\"The most important predictor variable is: {most_important_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae435717",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "The feature_importances_ attribute returns the importance score for each feature used in the model. These values represent the contribution of each feature to the model's decision-making process.\n",
    "The feature_names_in_ attribute corresponds to the names of the features that were used to train the model, helping us identify which feature has the highest importance.\n",
    "Reporting the Most Important Predictor:\n",
    "By plotting the importances, you'll be able to see which feature has the highest score. This feature is the most influential in predicting whether a book is hardcover or paperback in the clf2 model.\n",
    "\n",
    "Summary:\n",
    "Feature Importances:\n",
    "clf2.feature_importances_ provides the relative importance of each feature used in the decision tree model, showing how much each feature contributes to the model's predictions.\n",
    "clf2.feature_names_in_ corresponds to the feature names, helping to identify which predictors are most important.\n",
    "Visualization:\n",
    "A horizontal bar plot visualizes the feature importances, allowing you to quickly assess which features are most influential in the model.\n",
    "Most Important Feature:\n",
    "The most important predictor variable is the feature with the highest value in feature_importances_. This can be easily identified and reported by finding the feature corresponding to the highest importance score.\n",
    "This process helps to understand the contribution of different features in a complex decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5a043",
   "metadata": {},
   "source": [
    "question9\n",
    "In linear regression, coefficients represent the direct effect of each predictor variable on the target variable, where the magnitude and sign indicate the strength and direction of the relationship. In contrast, feature importances in decision trees reflect how valuable each feature is in making accurate splits at each decision node, but they don't directly quantify the relationship between the feature and the target. While linear regression offers a clear, linear relationship, decision trees capture complex, non-linear interactions between features and outcomes.\n",
    "\n",
    "Summary:\n",
    "Linear Regression: Coefficients show the direct effect of each feature on the target, with the magnitude and sign indicating the strength and direction of the relationship.\n",
    "Decision Trees: Feature importances indicate how useful each feature is in making decision splits, but do not directly quantify the relationship between the feature and the target. Decision trees capture complex, non-linear interactions, unlike linear regression’s linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383565f",
   "metadata": {},
   "source": [
    "question10\n",
    "yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
